<!DOCTYPE html>
<meta charset="utf-8"> 
<html lang="en">
        
<head>
    <title>音频测试</title>
</head>
<body>
<!--<canvas id="canvas"></canvas>-->
<p>
    最大音量： <input  type="text" id="maxAudio"></input>
</p>
<p>
    实时音量：<input   type="text"  id="autoAudio"></input>
</p>

<div id='debug' width="100%">
</div>

</body>

<!--<script src="vudio.js"></script>-->
<script type="text/javascript">
  // var canvas = document.querySelector('#canvas')

(function() {

	var promisifiedOldGUM = function(constraints, successCallback, errorCallback) {

		// First get ahold of getUserMedia, if present
		var getUserMedia = (navigator.getUserMedia ||
				navigator.webkitGetUserMedia ||
				navigator.mozGetUserMedia ||
				navigator.msGetUserMedia);

		// Some browsers just don't implement it - return a rejected promise with an error
		// to keep a consistent interface
		if(!getUserMedia) {
			return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
		}

		// Otherwise, wrap the call to the old navigator.getUserMedia with a Promise
		return new Promise(function(successCallback, errorCallback) {
			getUserMedia.call(navigator, constraints, successCallback, errorCallback);
		});
		
	}

	// Older browsers might not implement mediaDevices at all, so we set an empty object first
	if(navigator.mediaDevices === undefined) {
		navigator.mediaDevices = {};
	}

	// Some browsers partially implement mediaDevices. We can't just assign an object
	// with getUserMedia as it would overwrite existing properties.
	// Here, we will just add the getUserMedia property if it's missing.
	if(navigator.mediaDevices.getUserMedia === undefined) {
		navigator.mediaDevices.getUserMedia = promisifiedOldGUM;
	}
	
})();
        
  function debug(msg){
      var elem = document.getElementById('debug');
      var p = document.createElement('p');
      p.innerText = msg;
      elem.appendChild(p);
  }

  var maxNum = 0;
  var maxAudio = document.getElementById("maxAudio");
  var autoAudio = document.getElementById("autoAudio");

  debug(navigator.mediaDevices);

  navigator.mediaDevices.getUserMedia({
    audio: true
  }).then((stream) => {
          debug('aaa');
      // 1. 创建AudioContext音频对象
      var audioContext = new (window.AudioContext || window.webkitAudioContext || window.mozAudioContext) ();
      // 2. stream参数传入，以实现将麦克风音频输入该AudioContext对象
       var source = Object.prototype.toString.call(stream) !== '[object MediaStream]' ? audioContext.createMediaElementSource(stream) : audioContext.createMediaStreamSource(stream);

      // 3.创建音频分析对象
      // 在该对象中指定采样的缓冲区域大小，该值一般为256、512、1024、2048、4096、8192、16384中的一种，数字越大则采样缓冲区越大，对应的audioprocess事件的触发频率也越低，数字越小则反之，在此将该参数设置为4096
      // 同时，设置音频分析的输入与输出都是 单声道，其参数为1（若要以 双声道 进行分析则可设置为2
      var  scriptNode =  audioContext.createScriptProcessor(4096,1,1);

      // 音频处理函数
      scriptNode.onaudioprocess = function(audioProcessingEvent) {
          var inputBuffer = audioProcessingEvent.inputBuffer;
          // var outputBuffer = audioProcessingEvent.outputBuffer;
          for (var channel = 0; channel < inputBuffer.numberOfChannels; channel++) {
              var inputData = inputBuffer.getChannelData(channel);
              for(var i= 0; i < inputData.length;i++){
                  var num = 10000 * inputData[i];
                  if(maxNum < num){
                      maxNum=num;
                  }
                  autoAudio.value= num;
                  var tmp=maxAudio.value;
                  if(tmp<maxNum){
                      maxAudio.value= maxNum;
                  }
              }

          }
      }
      source.connect(scriptNode);
      scriptNode.connect(audioContext.destination);
      // source.start();

  }).catch((error) => {
    debug('getUserMedia not supported on your browser!')
  })

</script>
</html>
